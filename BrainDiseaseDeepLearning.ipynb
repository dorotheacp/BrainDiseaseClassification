{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 18318007_MobileNetV3_fold10_fix.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SzZhXdMyF1_d",
        "j8ftrzNliS0b",
        "eHh6AJfmAyg5",
        "35Jygz99Aj2y",
        "ZEvXwYLjBtEo"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nao3H3EkLkci"
      },
      "source": [
        "**Dorothea Claresta P (18318007)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlZETuz8k_nQ"
      },
      "source": [
        "# **Importing Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVxDrjHYigGI"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "torch.cuda.empty_cache()\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor, Resize, Compose\n",
        "from torch.utils.data import ConcatDataset\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LnASeLtVikt",
        "outputId": "3ca6058d-cbc0-4280-ffff-cb4c0cb6299c"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Ho0YAP7QFx"
      },
      "source": [
        "# **Getting NISN Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PovmZPb4IxR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6150f87-191c-4304-e224-638fa69b67de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive2', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc0voda27wkR"
      },
      "source": [
        "# **Training and Validation Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwbI889a7-UL"
      },
      "source": [
        "## **Defining Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPhoFhNulNH6",
        "outputId": "267eba7a-5a36-4066-b0cd-beda7423e326"
      },
      "source": [
        "fold = 10 # no. of kfold\n",
        "img_size = 320\n",
        "\n",
        "train_ds_list = []\n",
        "for i in range(1, 11):\n",
        "  if i != fold:\n",
        "    train_ds_i = ImageFolder(\n",
        "        '/content/drive2/MyDrive/10folds/fold'+str(i)+'/',\n",
        "        transform=Compose([Resize((img_size, img_size)),\n",
        "                           ToTensor()]))\n",
        "    print('Jumlah train dataset dari fold %d: %d' % (i, len(train_ds_i)))\n",
        "    train_ds_list.append(train_ds_i)\n",
        "\n",
        "train_ds = ConcatDataset(train_ds_list)\n",
        "print('\\nJumlah train dataset total: %d' % len(train_ds))\n",
        "\n",
        "val_ds = ImageFolder(\n",
        "    '/content/drive2/MyDrive/10folds/fold'+str(fold)+'/',\n",
        "    transform=Compose([Resize((img_size, img_size)),\n",
        "                        ToTensor()]))\n",
        "print('Jumlah val dataset (fold %d): %d' % (fold, len(val_ds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah train dataset dari fold 1: 528\n",
            "Jumlah train dataset dari fold 2: 529\n",
            "Jumlah train dataset dari fold 3: 529\n",
            "Jumlah train dataset dari fold 4: 528\n",
            "Jumlah train dataset dari fold 5: 528\n",
            "Jumlah train dataset dari fold 6: 529\n",
            "Jumlah train dataset dari fold 7: 528\n",
            "Jumlah train dataset dari fold 8: 528\n",
            "Jumlah train dataset dari fold 9: 529\n",
            "\n",
            "Jumlah train dataset total: 4756\n",
            "Jumlah val dataset (fold 10): 529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYX6GSDn9OV-"
      },
      "source": [
        "## **Data Loaders for Training and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaGCs1-_3xMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679a9d2e-5d80-4096-ff27-1210141ae09a"
      },
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size = 40\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U21mrEXe9YOG"
      },
      "source": [
        "## **Showing Batch in Grid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wUAwd8x31IE"
      },
      "source": [
        "# from torchvision.utils import make_grid\n",
        "\n",
        "# def show_batch(dl):\n",
        "#     for images, labels in dl:\n",
        "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
        "#         ax.set_xticks([]); ax.set_yticks([])\n",
        "#         ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "#         break\n",
        "\n",
        "# show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0p50Ttb9hn_"
      },
      "source": [
        "# **Model & Helper Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffpDFbUGf03k"
      },
      "source": [
        "## **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW_xsULZZH6U"
      },
      "source": [
        "\"\"\"\n",
        "Creates a MobileNetV3 Model as defined in:\n",
        "Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam. (2019).\n",
        "Searching for MobileNetV3\n",
        "arXiv preprint arXiv:1905.02244.\n",
        "\n",
        "https://github.com/d-li14/mobilenetv3.pytorch/blob/master/mobilenetv3.py\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "__all__ = ['mobilenetv3_large', 'mobilenetv3_small']\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class h_sigmoid(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_sigmoid, self).__init__()\n",
        "        self.relu = nn.ReLU6(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + 3) / 6\n",
        "\n",
        "\n",
        "class h_swish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_swish, self).__init__()\n",
        "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)\n",
        "\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(channel, _make_divisible(channel // reduction, 8)),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(_make_divisible(channel // reduction, 8), channel),\n",
        "                h_sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "def conv_3x3_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        h_swish()\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        h_swish()\n",
        "    )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, hidden_dim, oup, kernel_size, stride, use_se, use_hs):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        self.identity = stride == 1 and inp == oup\n",
        "\n",
        "        if inp == hidden_dim:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
        "                # Squeeze-and-Excite\n",
        "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                # Squeeze-and-Excite\n",
        "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
        "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.identity:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self, cfgs, mode, in_channels=3, use_auxiliary=False, num_classes=37, width_mult=1.):\n",
        "        super(MobileNetV3, self).__init__()\n",
        "        # setting of inverted residual blocks\n",
        "        self.cfgs = cfgs\n",
        "        assert mode in ['large', 'small']\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(16 * width_mult, 8)\n",
        "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        block = InvertedResidual\n",
        "        for k, t, c, use_se, use_hs, s in self.cfgs:\n",
        "            output_channel = _make_divisible(c * width_mult, 8)\n",
        "            exp_size = _make_divisible(input_channel * t, 8)\n",
        "            layers.append(block(input_channel, exp_size, output_channel, k, s, use_se, use_hs))\n",
        "            input_channel = output_channel\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        # building last several layers\n",
        "        self.conv = conv_1x1_bn(input_channel, exp_size)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        output_channel = {'large': 1280, 'small': 1024}\n",
        "        output_channel = _make_divisible(output_channel[mode] * width_mult, 8) if width_mult > 1.0 else output_channel[mode]\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(exp_size, output_channel),\n",
        "            h_swish(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(output_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def mobilenetv3_large(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a MobileNetV3-Large model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # k, t, c, SE, HS, s \n",
        "        [3,   1,  16, 0, 0, 1],\n",
        "        [3,   4,  24, 0, 0, 2],\n",
        "        [3,   3,  24, 0, 0, 1],\n",
        "        [5,   3,  40, 1, 0, 2],\n",
        "        [5,   3,  40, 1, 0, 1],\n",
        "        [5,   3,  40, 1, 0, 1],\n",
        "        [3,   6,  80, 0, 1, 2],\n",
        "        [3, 2.5,  80, 0, 1, 1],\n",
        "        [3, 2.3,  80, 0, 1, 1],\n",
        "        [3, 2.3,  80, 0, 1, 1],\n",
        "        [3,   6, 112, 1, 1, 1],\n",
        "        [3,   6, 112, 1, 1, 1],\n",
        "        [5,   6, 160, 1, 1, 2],\n",
        "        [5,   6, 160, 1, 1, 1],\n",
        "        [5,   6, 160, 1, 1, 1]\n",
        "    ]\n",
        "    return MobileNetV3(cfgs, mode='large', **kwargs)\n",
        "\n",
        "\n",
        "def mobilenetv3_small(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a MobileNetV3-Small model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # k, t, c, SE, HS, s \n",
        "        [3,    1,  16, 1, 0, 2],\n",
        "        [3,  4.5,  24, 0, 0, 2],\n",
        "        [3, 3.67,  24, 0, 0, 1],\n",
        "        [5,    4,  40, 1, 1, 2],\n",
        "        [5,    6,  40, 1, 1, 1],\n",
        "        [5,    6,  40, 1, 1, 1],\n",
        "        [5,    3,  48, 1, 1, 1],\n",
        "        [5,    3,  48, 1, 1, 1],\n",
        "        [5,    6,  96, 1, 1, 2],\n",
        "        [5,    6,  96, 1, 1, 1],\n",
        "        [5,    6,  96, 1, 1, 1],\n",
        "    ]\n",
        "\n",
        "    return MobileNetV3(cfgs, mode='small', **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZhXdMyF1_d"
      },
      "source": [
        "## **Train Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTCFFr9DhMO"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50):\n",
        "    \n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_time = time.time()\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
        "                    \n",
        "                    if phase == 'train': # Backward + optimize only if in training phase\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                            \n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    \n",
        "                    if phase == 'val':\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            if phase == 'val': # Adjust learning rate based on val loss\n",
        "                lr_scheduler.step(epoch_loss)\n",
        "                \n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_accs.append(epoch_acc)\n",
        "            if phase == 'val':\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_accs.append(epoch_acc)\n",
        "\n",
        "        epoch_time_elapsed = time.time() - epoch_time\n",
        "        print('{:.0f}m {:.0f}s\\n'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_losses, train_accs, val_losses, val_accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSPlIEhoBcFQ"
      },
      "source": [
        "## **Defining Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j9OpIcYBakO",
        "outputId": "698746d1-7b08-449e-86a3-fb1578135d4a"
      },
      "source": [
        "model = mobilenetv3_large()\n",
        "model.to(device)\n",
        "next(model.parameters()).is_cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAh3x-Fl6mf5"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8ftrzNliS0b"
      },
      "source": [
        "## **Initial Accuracy and Loss on Val. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN1YpJwJiS0l",
        "outputId": "404a81d7-40ee-437c-f0d9-41a437f187d4"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.eval().cuda()\n",
        "\n",
        "run_loss = 0\n",
        "correct = 0\n",
        "with  torch.no_grad():\n",
        "    for inputs, labels in val_dl:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Make predictions.\n",
        "        prediction = model(inputs)\n",
        "\n",
        "        # Retrieve predictions indexes.\n",
        "        loss = criterion(prediction.data, labels)\n",
        "        _, predicted_class = torch.max(prediction.data, 1)\n",
        "\n",
        "        # Compute number of correct predictions.\n",
        "        run_loss += loss.item() * inputs.size(0)\n",
        "        correct += (predicted_class == labels).float().sum().item()\n",
        "\n",
        "val_loss = run_loss / len(val_dl.dataset)\n",
        "val_accuracy = correct / len(val_dl.dataset)\n",
        "print('Val Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 3.6109 Acc: 0.3308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq747D5GF_G-"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOMeDP78BmvL"
      },
      "source": [
        "epochs = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3xWGYk9Dqlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e39bfc-1cac-46e6-cfd3-a471359f729e"
      },
      "source": [
        "model, train_losses, train_accs, val_losses, val_accs = train_model(model, {\"train\": train_dl, \"val\": val_dl}, criterion, optimizer, epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.5854 Acc: 0.3219\n",
            "val Loss: 2.4835 Acc: 0.3100\n",
            "10m 30s\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "train Loss: 2.3709 Acc: 0.3370\n",
            "val Loss: 2.4626 Acc: 0.3289\n",
            "1m 22s\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "train Loss: 2.1413 Acc: 0.3707\n",
            "val Loss: 2.3684 Acc: 0.3100\n",
            "1m 22s\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "train Loss: 1.9387 Acc: 0.4151\n",
            "val Loss: 2.2908 Acc: 0.3138\n",
            "1m 22s\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "train Loss: 1.7013 Acc: 0.4712\n",
            "val Loss: 2.1712 Acc: 0.3686\n",
            "1m 22s\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "train Loss: 1.4533 Acc: 0.5275\n",
            "val Loss: 1.7390 Acc: 0.4499\n",
            "1m 22s\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "train Loss: 1.2696 Acc: 0.5839\n",
            "val Loss: 1.6823 Acc: 0.4764\n",
            "1m 22s\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "train Loss: 1.0207 Acc: 0.6613\n",
            "val Loss: 1.9799 Acc: 0.4518\n",
            "1m 21s\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "train Loss: 0.8942 Acc: 0.6974\n",
            "val Loss: 1.0047 Acc: 0.6616\n",
            "1m 21s\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "train Loss: 0.7006 Acc: 0.7778\n",
            "val Loss: 1.1017 Acc: 0.6749\n",
            "1m 22s\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "train Loss: 0.6088 Acc: 0.7979\n",
            "val Loss: 1.0770 Acc: 0.6692\n",
            "1m 22s\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "train Loss: 0.5252 Acc: 0.8234\n",
            "val Loss: 1.1736 Acc: 0.6749\n",
            "1m 22s\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "train Loss: 0.4199 Acc: 0.8585\n",
            "val Loss: 1.3091 Acc: 0.6597\n",
            "1m 22s\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "train Loss: 0.3516 Acc: 0.8852\n",
            "val Loss: 0.8788 Acc: 0.7335\n",
            "1m 22s\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "train Loss: 0.3028 Acc: 0.9005\n",
            "val Loss: 1.3085 Acc: 0.6824\n",
            "1m 22s\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "train Loss: 0.2751 Acc: 0.9102\n",
            "val Loss: 1.0593 Acc: 0.7164\n",
            "1m 22s\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "train Loss: 0.2217 Acc: 0.9279\n",
            "val Loss: 1.2088 Acc: 0.6843\n",
            "1m 22s\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "train Loss: 0.2482 Acc: 0.9153\n",
            "val Loss: 1.1995 Acc: 0.7221\n",
            "1m 22s\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "train Loss: 0.2206 Acc: 0.9279\n",
            "val Loss: 0.9721 Acc: 0.7769\n",
            "1m 22s\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "train Loss: 0.1939 Acc: 0.9380\n",
            "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
            "val Loss: 0.9270 Acc: 0.7580\n",
            "1m 22s\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "train Loss: 0.1022 Acc: 0.9685\n",
            "val Loss: 0.4489 Acc: 0.8790\n",
            "1m 22s\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "train Loss: 0.0329 Acc: 0.9926\n",
            "val Loss: 0.4412 Acc: 0.8752\n",
            "1m 22s\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "train Loss: 0.0249 Acc: 0.9954\n",
            "val Loss: 0.4343 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "train Loss: 0.0190 Acc: 0.9966\n",
            "val Loss: 0.4311 Acc: 0.8866\n",
            "1m 22s\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "train Loss: 0.0143 Acc: 0.9985\n",
            "val Loss: 0.4411 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "train Loss: 0.0168 Acc: 0.9968\n",
            "val Loss: 0.4556 Acc: 0.8847\n",
            "1m 22s\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "train Loss: 0.0124 Acc: 0.9979\n",
            "val Loss: 0.4388 Acc: 0.8998\n",
            "1m 22s\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "train Loss: 0.0095 Acc: 0.9987\n",
            "val Loss: 0.4476 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "train Loss: 0.0078 Acc: 0.9992\n",
            "val Loss: 0.4340 Acc: 0.8960\n",
            "1m 22s\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "train Loss: 0.0087 Acc: 0.9985\n",
            "Epoch    30: reducing learning rate of group 0 to 1.0000e-05.\n",
            "val Loss: 0.4429 Acc: 0.8866\n",
            "1m 22s\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "train Loss: 0.0068 Acc: 0.9992\n",
            "val Loss: 0.4531 Acc: 0.8828\n",
            "1m 22s\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "train Loss: 0.0072 Acc: 0.9989\n",
            "val Loss: 0.4534 Acc: 0.8979\n",
            "1m 21s\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "train Loss: 0.0060 Acc: 0.9996\n",
            "val Loss: 0.4633 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "train Loss: 0.0069 Acc: 0.9989\n",
            "val Loss: 0.4629 Acc: 0.8847\n",
            "1m 22s\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "train Loss: 0.0076 Acc: 0.9989\n",
            "val Loss: 0.4548 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "train Loss: 0.0066 Acc: 0.9994\n",
            "Epoch    36: reducing learning rate of group 0 to 1.0000e-06.\n",
            "val Loss: 0.4535 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9989\n",
            "val Loss: 0.4418 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "train Loss: 0.0051 Acc: 0.9996\n",
            "val Loss: 0.4438 Acc: 0.8922\n",
            "1m 21s\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "train Loss: 0.0063 Acc: 0.9994\n",
            "val Loss: 0.4604 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "train Loss: 0.0053 Acc: 0.9996\n",
            "val Loss: 0.4426 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "train Loss: 0.0059 Acc: 0.9998\n",
            "val Loss: 0.4537 Acc: 0.8866\n",
            "1m 22s\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "train Loss: 0.0060 Acc: 0.9989\n",
            "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
            "val Loss: 0.4630 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "train Loss: 0.0067 Acc: 0.9996\n",
            "val Loss: 0.4658 Acc: 0.8866\n",
            "1m 22s\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "train Loss: 0.0050 Acc: 0.9998\n",
            "val Loss: 0.4597 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "train Loss: 0.0068 Acc: 0.9992\n",
            "val Loss: 0.4607 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "train Loss: 0.0054 Acc: 0.9996\n",
            "val Loss: 0.4615 Acc: 0.8847\n",
            "1m 22s\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9992\n",
            "val Loss: 0.4625 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "train Loss: 0.0059 Acc: 0.9998\n",
            "Epoch    48: reducing learning rate of group 0 to 1.0000e-08.\n",
            "val Loss: 0.4537 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "train Loss: 0.0049 Acc: 0.9998\n",
            "val Loss: 0.4539 Acc: 0.8866\n",
            "1m 22s\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "train Loss: 0.0052 Acc: 0.9998\n",
            "val Loss: 0.4512 Acc: 0.8979\n",
            "1m 22s\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "train Loss: 0.0049 Acc: 1.0000\n",
            "val Loss: 0.4532 Acc: 0.8922\n",
            "1m 23s\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "train Loss: 0.0061 Acc: 0.9992\n",
            "val Loss: 0.4587 Acc: 0.8922\n",
            "1m 23s\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "train Loss: 0.0058 Acc: 0.9994\n",
            "val Loss: 0.4508 Acc: 0.8998\n",
            "1m 23s\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "train Loss: 0.0064 Acc: 0.9989\n",
            "val Loss: 0.4390 Acc: 0.8941\n",
            "1m 23s\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "train Loss: 0.0070 Acc: 0.9989\n",
            "val Loss: 0.4623 Acc: 0.8885\n",
            "1m 23s\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "train Loss: 0.0070 Acc: 0.9992\n",
            "val Loss: 0.4571 Acc: 0.8979\n",
            "1m 23s\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9994\n",
            "val Loss: 0.4562 Acc: 0.8941\n",
            "1m 23s\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "train Loss: 0.0061 Acc: 0.9994\n",
            "val Loss: 0.4647 Acc: 0.8885\n",
            "1m 23s\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "train Loss: 0.0070 Acc: 0.9992\n",
            "val Loss: 0.4446 Acc: 0.8960\n",
            "1m 23s\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "train Loss: 0.0055 Acc: 0.9998\n",
            "val Loss: 0.4662 Acc: 0.8847\n",
            "1m 23s\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "train Loss: 0.0058 Acc: 0.9998\n",
            "val Loss: 0.4766 Acc: 0.8904\n",
            "1m 23s\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "train Loss: 0.0060 Acc: 0.9996\n",
            "val Loss: 0.4558 Acc: 0.8885\n",
            "1m 23s\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "train Loss: 0.0054 Acc: 0.9998\n",
            "val Loss: 0.4639 Acc: 0.9036\n",
            "1m 23s\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "train Loss: 0.0052 Acc: 0.9996\n",
            "val Loss: 0.4831 Acc: 0.8922\n",
            "1m 23s\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "train Loss: 0.0069 Acc: 0.9989\n",
            "val Loss: 0.4515 Acc: 0.8866\n",
            "1m 23s\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "train Loss: 0.0058 Acc: 0.9994\n",
            "val Loss: 0.4523 Acc: 0.8922\n",
            "1m 23s\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "train Loss: 0.0073 Acc: 0.9987\n",
            "val Loss: 0.4518 Acc: 0.8998\n",
            "1m 23s\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "train Loss: 0.0073 Acc: 0.9985\n",
            "val Loss: 0.4697 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "train Loss: 0.0070 Acc: 0.9989\n",
            "val Loss: 0.4519 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "train Loss: 0.0064 Acc: 0.9996\n",
            "val Loss: 0.4605 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "train Loss: 0.0056 Acc: 0.9994\n",
            "val Loss: 0.4513 Acc: 0.8960\n",
            "1m 22s\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "train Loss: 0.0046 Acc: 0.9998\n",
            "val Loss: 0.4667 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "train Loss: 0.0074 Acc: 0.9989\n",
            "val Loss: 0.4432 Acc: 0.8998\n",
            "1m 22s\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "train Loss: 0.0060 Acc: 0.9994\n",
            "val Loss: 0.4588 Acc: 0.8979\n",
            "1m 22s\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "train Loss: 0.0055 Acc: 0.9996\n",
            "val Loss: 0.4559 Acc: 0.8941\n",
            "1m 23s\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "train Loss: 0.0057 Acc: 0.9989\n",
            "val Loss: 0.4474 Acc: 0.8998\n",
            "1m 23s\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "train Loss: 0.0072 Acc: 0.9994\n",
            "val Loss: 0.4670 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "train Loss: 0.0061 Acc: 0.9996\n",
            "val Loss: 0.4663 Acc: 0.8828\n",
            "1m 22s\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "train Loss: 0.0068 Acc: 0.9992\n",
            "val Loss: 0.4623 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "train Loss: 0.0054 Acc: 0.9994\n",
            "val Loss: 0.4634 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "train Loss: 0.0056 Acc: 0.9998\n",
            "val Loss: 0.4525 Acc: 0.8960\n",
            "1m 22s\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "train Loss: 0.0054 Acc: 0.9998\n",
            "val Loss: 0.4600 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "train Loss: 0.0059 Acc: 0.9994\n",
            "val Loss: 0.4537 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "train Loss: 0.0068 Acc: 0.9992\n",
            "val Loss: 0.4523 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "train Loss: 0.0059 Acc: 0.9996\n",
            "val Loss: 0.4460 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "train Loss: 0.0067 Acc: 0.9987\n",
            "val Loss: 0.4501 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9994\n",
            "val Loss: 0.4609 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "train Loss: 0.0058 Acc: 0.9994\n",
            "val Loss: 0.4630 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "train Loss: 0.0055 Acc: 0.9998\n",
            "val Loss: 0.4493 Acc: 0.8904\n",
            "1m 22s\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "train Loss: 0.0065 Acc: 0.9996\n",
            "val Loss: 0.4580 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "train Loss: 0.0056 Acc: 1.0000\n",
            "val Loss: 0.4361 Acc: 0.8979\n",
            "1m 23s\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "train Loss: 0.0069 Acc: 0.9992\n",
            "val Loss: 0.4528 Acc: 0.8885\n",
            "1m 22s\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "train Loss: 0.0076 Acc: 0.9989\n",
            "val Loss: 0.4507 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "train Loss: 0.0056 Acc: 0.9996\n",
            "val Loss: 0.4607 Acc: 0.8941\n",
            "1m 22s\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "train Loss: 0.0059 Acc: 0.9998\n",
            "val Loss: 0.4494 Acc: 0.8922\n",
            "1m 23s\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n",
            "train Loss: 0.0051 Acc: 0.9996\n",
            "val Loss: 0.4580 Acc: 0.8771\n",
            "1m 23s\n",
            "\n",
            "Epoch 97/100\n",
            "----------\n",
            "train Loss: 0.0051 Acc: 0.9998\n",
            "val Loss: 0.4489 Acc: 0.8979\n",
            "1m 22s\n",
            "\n",
            "Epoch 98/100\n",
            "----------\n",
            "train Loss: 0.0071 Acc: 0.9987\n",
            "val Loss: 0.4627 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 99/100\n",
            "----------\n",
            "train Loss: 0.0067 Acc: 0.9996\n",
            "val Loss: 0.4484 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Epoch 100/100\n",
            "----------\n",
            "train Loss: 0.0054 Acc: 0.9998\n",
            "val Loss: 0.4541 Acc: 0.8922\n",
            "1m 22s\n",
            "\n",
            "Training complete in 146m 11s\n",
            "Best val Acc: 0.903592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUy8bUz1RR34"
      },
      "source": [
        "## **Final Accuracy and Loss on Val. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKkOND9QA1Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bec8f62-09ff-4416-a5b3-31ad7c0b94bb"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.eval().cuda()\n",
        "\n",
        "run_loss = 0\n",
        "correct = 0\n",
        "with  torch.no_grad():\n",
        "    for inputs, labels in val_dl:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Make predictions.\n",
        "        prediction = model(inputs)\n",
        "\n",
        "        # Retrieve predictions indexes.\n",
        "        loss = criterion(prediction.data, labels)\n",
        "        _, predicted_class = torch.max(prediction.data, 1)\n",
        "\n",
        "        # Compute number of correct predictions.\n",
        "        run_loss += loss.item() * inputs.size(0)\n",
        "        correct += (predicted_class == labels).float().sum().item()\n",
        "\n",
        "val_loss = run_loss / len(val_dl.dataset)\n",
        "val_accuracy = correct / len(val_dl.dataset)\n",
        "print('Val Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4639 Acc: 0.9036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbLKc5jA82GQ"
      },
      "source": [
        "# **Save / Load Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9fdrqNQb127"
      },
      "source": [
        "## **Saving Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6j_VuwjdLTm"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/model_fold'+str(fold)+'.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3MF4EXRE1g"
      },
      "source": [
        "## **Loading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c_8FQOId5LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b1f415-670f-4bf9-c0e7-85431f007f87"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = mobilenetv3_large()\n",
        "model.load_state_dict(torch.load('/content/model_fold'+str(fold)+'.pt', map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV3(\n",
              "  (features): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): h_swish(\n",
              "        (sigmoid): h_sigmoid(\n",
              "          (relu): ReLU6(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Identity()\n",
              "        (4): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=72, out_features=24, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=24, out_features=72, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=120, out_features=32, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=32, out_features=120, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=120, out_features=32, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=32, out_features=120, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "        (4): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "        (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "        (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): Identity()\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=480, out_features=120, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=120, out_features=480, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "        (4): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=672, out_features=168, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=168, out_features=672, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "        (4): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=672, out_features=168, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=168, out_features=672, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=960, out_features=240, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=240, out_features=960, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (3): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): SELayer(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc): Sequential(\n",
              "            (0): Linear(in_features=960, out_features=240, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=240, out_features=960, bias=True)\n",
              "            (3): h_sigmoid(\n",
              "              (relu): ReLU6(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): h_swish(\n",
              "          (sigmoid): h_sigmoid(\n",
              "            (relu): ReLU6(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (7): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (8): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): h_swish(\n",
              "      (sigmoid): h_sigmoid(\n",
              "        (relu): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
              "    (1): h_swish(\n",
              "      (sigmoid): h_sigmoid(\n",
              "        (relu): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=1280, out_features=37, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLy7M2a8_ds"
      },
      "source": [
        "# **Plot Loss & Accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHh6AJfmAyg5"
      },
      "source": [
        "## **Plot Loss vs No. of Epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04HU8fv_A4uE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8e0890e8-8b76-4062-ec0d-6cb3f9dfda72"
      },
      "source": [
        "plt.plot(train_losses, '-b')\n",
        "plt.plot(val_losses, '-r')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plt.savefig('plot_loss'+str(fold)+'.png')\n",
        "print(val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.463922724155938\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Jygz99Aj2y"
      },
      "source": [
        "## **Plot Accuracy vs No. of Epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQsZrdIV7H_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7f3004fb-92a7-4e8e-c710-44b92bed82dc"
      },
      "source": [
        "plt.plot(train_accs, '-b')\n",
        "plt.plot(val_accs, '-r')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plt.savefig('plot_acc'+str(fold)+'.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEvXwYLjBtEo"
      },
      "source": [
        "## **Plot Print**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6ZrC6DB8K42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2575480b-fa47-433e-b732-8c44f0351199"
      },
      "source": [
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  # train_loss_list.append(train_loss[i].item())\n",
        "  train_acc_list.append(train_accs[i].item())\n",
        "  # val_loss_list.append(val_loss[i].item())\n",
        "  val_acc_list.append(val_accs[i].item())\n",
        "\n",
        "data = {'train_loss': train_losses, 'train_acc': train_acc_list,\n",
        "        'val_loss': val_losses, 'val_acc': val_acc_list}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('data_fold'+str(fold)+'.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.585410</td>\n",
              "      <td>0.321909</td>\n",
              "      <td>2.483520</td>\n",
              "      <td>0.310019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.370892</td>\n",
              "      <td>0.337048</td>\n",
              "      <td>2.462643</td>\n",
              "      <td>0.328922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.141322</td>\n",
              "      <td>0.370690</td>\n",
              "      <td>2.368378</td>\n",
              "      <td>0.310019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.938659</td>\n",
              "      <td>0.415055</td>\n",
              "      <td>2.290846</td>\n",
              "      <td>0.313800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.701299</td>\n",
              "      <td>0.471194</td>\n",
              "      <td>2.171247</td>\n",
              "      <td>0.368620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.999579</td>\n",
              "      <td>0.458050</td>\n",
              "      <td>0.877127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.005149</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.448897</td>\n",
              "      <td>0.897921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.007132</td>\n",
              "      <td>0.998738</td>\n",
              "      <td>0.462683</td>\n",
              "      <td>0.892250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.006662</td>\n",
              "      <td>0.999579</td>\n",
              "      <td>0.448415</td>\n",
              "      <td>0.892250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.005352</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.454057</td>\n",
              "      <td>0.892250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    train_loss  train_acc  val_loss   val_acc\n",
              "0     2.585410   0.321909  2.483520  0.310019\n",
              "1     2.370892   0.337048  2.462643  0.328922\n",
              "2     2.141322   0.370690  2.368378  0.310019\n",
              "3     1.938659   0.415055  2.290846  0.313800\n",
              "4     1.701299   0.471194  2.171247  0.368620\n",
              "..         ...        ...       ...       ...\n",
              "95    0.005103   0.999579  0.458050  0.877127\n",
              "96    0.005149   0.999790  0.448897  0.897921\n",
              "97    0.007132   0.998738  0.462683  0.892250\n",
              "98    0.006662   0.999579  0.448415  0.892250\n",
              "99    0.005352   0.999790  0.454057  0.892250\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}